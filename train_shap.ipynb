{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636adbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 286843 × 28913\n",
      "    obs: 'sample', 'tissue', 'patient', 'n_genes_by_counts', 'total_counts', 'total_counts_rp', 'pct_counts_rp', 'total_counts_mt', 'pct_counts_mt', 'total_counts_hb', 'pct_counts_hb', 'total_counts_hsp', 'pct_counts_hsp', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'n_genes', 'S_score', 'G2M_score', 'phase', 'UMAP_1', 'UMAP_2', 'sub_cluster', 'major_cluster', 'batch', 'cell_type', 'response', 'pre_post'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "os.chdir('/mnt/data/wangw/AFS/赵路晴/test')\n",
    "filepath = '/mnt/data/wangw/AFS/赵路晴/test/test_adata_combined.h5ad'\n",
    "file ='/mnt/data/wangw/AFS/赵路晴/test/model_reult.pickle'\n",
    "model_reult = pickle.load(open(file,'rb'))\n",
    "import scanpy as sc\n",
    "count = 0\n",
    "adata = None\n",
    "if os.path.exists(\"test_adata_combined.pickle\"):\n",
    "    adata = pickle.load(open(\"test_adata_combined.pickle\",'rb'))\n",
    "else:\n",
    "    adata = sc.read_h5ad(filepath)\n",
    "    with open(\"test_adata_combined.pickle\", \"wb\") as f:\n",
    "        pickle.dump(adata, f)\n",
    "while not adata:\n",
    "    try:\n",
    "        adata = sc.read_h5ad(filepath)\n",
    "        with open(\"test_adata_combined.pickle\", \"wb\") as f:\n",
    "            pickle.dump(adata, f)\n",
    "    except Exception as e:\n",
    "        count+=1\n",
    "        print('try num :',count)\n",
    "\n",
    "acc, auc_val, fpr, tpr, model, X_test, adata_test, le,metrics_list,types_clean,dflist =model_reult['all']['XGBoost']\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66338b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28913)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adata_test.var),len(adata.var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f54ba6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_post 列的唯一值: ['post', 'pre']\n",
      "筛选后 pre_post == 'pre' 的样本量: 98270\n",
      "筛选后 pre_post == 'Pre' 的样本量: 98270\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>tissue</th>\n",
       "      <th>patient</th>\n",
       "      <th>n_genes_by_counts</th>\n",
       "      <th>total_counts</th>\n",
       "      <th>total_counts_rp</th>\n",
       "      <th>pct_counts_rp</th>\n",
       "      <th>total_counts_mt</th>\n",
       "      <th>pct_counts_mt</th>\n",
       "      <th>total_counts_hb</th>\n",
       "      <th>pct_counts_hb</th>\n",
       "      <th>total_counts_hsp</th>\n",
       "      <th>pct_counts_hsp</th>\n",
       "      <th>doublet_scores</th>\n",
       "      <th>predicted_doublets</th>\n",
       "      <th>doublet_info</th>\n",
       "      <th>n_genes</th>\n",
       "      <th>S_score</th>\n",
       "      <th>G2M_score</th>\n",
       "      <th>phase</th>\n",
       "      <th>UMAP_1</th>\n",
       "      <th>UMAP_2</th>\n",
       "      <th>sub_cluster</th>\n",
       "      <th>major_cluster</th>\n",
       "      <th>batch</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>response</th>\n",
       "      <th>pre_post</th>\n",
       "      <th>Cell_Type</th>\n",
       "      <th>Cancer_type_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P16-pre-P-CD8p2-GGCGACTTCCACGTTC-1</th>\n",
       "      <td>P16-pre-P-CD8p</td>\n",
       "      <td>P</td>\n",
       "      <td>P16</td>\n",
       "      <td>1427</td>\n",
       "      <td>4671.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>33.012203</td>\n",
       "      <td>154.0</td>\n",
       "      <td>3.296938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.278313</td>\n",
       "      <td>0.087618</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1427</td>\n",
       "      <td>0.037808</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>S</td>\n",
       "      <td>-0.212849</td>\n",
       "      <td>2.458946</td>\n",
       "      <td>CD8_C03_CX3CR1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cd8</td>\n",
       "      <td>CD8T</td>\n",
       "      <td>non-responder</td>\n",
       "      <td>pre</td>\n",
       "      <td>CD8</td>\n",
       "      <td>HCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P16-pre-P-CD8p1-CACCACTCAACAACCT-1</th>\n",
       "      <td>P16-pre-P-CD8p</td>\n",
       "      <td>P</td>\n",
       "      <td>P16</td>\n",
       "      <td>1835</td>\n",
       "      <td>7281.0</td>\n",
       "      <td>3163.0</td>\n",
       "      <td>43.441833</td>\n",
       "      <td>264.0</td>\n",
       "      <td>3.625876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.206016</td>\n",
       "      <td>0.112999</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1835</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>-0.124453</td>\n",
       "      <td>G1</td>\n",
       "      <td>7.944293</td>\n",
       "      <td>-0.144074</td>\n",
       "      <td>CD8_C01_LEF1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cd8</td>\n",
       "      <td>CD8T</td>\n",
       "      <td>non-responder</td>\n",
       "      <td>pre</td>\n",
       "      <td>CD8</td>\n",
       "      <td>HCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P16-pre-P-CD8n-TATTACCGTCCAACTA-1</th>\n",
       "      <td>P16-pre-P-CD8n</td>\n",
       "      <td>P</td>\n",
       "      <td>P16</td>\n",
       "      <td>959</td>\n",
       "      <td>2529.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>39.383156</td>\n",
       "      <td>231.0</td>\n",
       "      <td>9.134046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.316331</td>\n",
       "      <td>0.133690</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>959</td>\n",
       "      <td>-0.188267</td>\n",
       "      <td>-0.082084</td>\n",
       "      <td>G1</td>\n",
       "      <td>5.682766</td>\n",
       "      <td>3.407964</td>\n",
       "      <td>CD8_C02_GPR183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cd8</td>\n",
       "      <td>CD8T</td>\n",
       "      <td>non-responder</td>\n",
       "      <td>pre</td>\n",
       "      <td>CD8</td>\n",
       "      <td>HCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P16-pre-T-CD8p-CTAATGGGTTCCATGA-1</th>\n",
       "      <td>P16-pre-T-CD8p</td>\n",
       "      <td>T</td>\n",
       "      <td>P16</td>\n",
       "      <td>1081</td>\n",
       "      <td>2505.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>19.800400</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.874251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.754491</td>\n",
       "      <td>0.064125</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1081</td>\n",
       "      <td>0.139061</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>S</td>\n",
       "      <td>0.651383</td>\n",
       "      <td>-3.216115</td>\n",
       "      <td>CD8_C08_GZMK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cd8</td>\n",
       "      <td>CD8T</td>\n",
       "      <td>non-responder</td>\n",
       "      <td>pre</td>\n",
       "      <td>CD8</td>\n",
       "      <td>HCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P16-pre-P-CD8p1-TGACTTTAGCGTGAGT-1</th>\n",
       "      <td>P16-pre-P-CD8p</td>\n",
       "      <td>P</td>\n",
       "      <td>P16</td>\n",
       "      <td>894</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>19.449036</td>\n",
       "      <td>205.0</td>\n",
       "      <td>11.294765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.222841</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>894</td>\n",
       "      <td>-0.032617</td>\n",
       "      <td>-0.149058</td>\n",
       "      <td>G1</td>\n",
       "      <td>0.857628</td>\n",
       "      <td>-1.018432</td>\n",
       "      <td>CD8_C08_GZMK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cd8</td>\n",
       "      <td>CD8T</td>\n",
       "      <td>non-responder</td>\n",
       "      <td>pre</td>\n",
       "      <td>CD8</td>\n",
       "      <td>HCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P18-pre-P-CTCTGGTCAGCGTAAG-1</th>\n",
       "      <td>P18-pre-P</td>\n",
       "      <td>P</td>\n",
       "      <td>P18</td>\n",
       "      <td>1396</td>\n",
       "      <td>2318.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>9.232097</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.141501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.121657</td>\n",
       "      <td>0.137306</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1396</td>\n",
       "      <td>0.041544</td>\n",
       "      <td>-0.059760</td>\n",
       "      <td>S</td>\n",
       "      <td>7.865705</td>\n",
       "      <td>-0.785990</td>\n",
       "      <td>CD8_C03_CX3CR1</td>\n",
       "      <td>CD8T</td>\n",
       "      <td>cd45</td>\n",
       "      <td>CD45</td>\n",
       "      <td>responder</td>\n",
       "      <td>pre</td>\n",
       "      <td>CD8</td>\n",
       "      <td>HCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P27-pre-T-TGAGGGAAGAAGGCCT-1</th>\n",
       "      <td>P27-pre-T</td>\n",
       "      <td>T</td>\n",
       "      <td>P27</td>\n",
       "      <td>1319</td>\n",
       "      <td>3377.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>30.944624</td>\n",
       "      <td>137.0</td>\n",
       "      <td>4.056855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>3.879183</td>\n",
       "      <td>0.045350</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1319</td>\n",
       "      <td>0.100014</td>\n",
       "      <td>0.030680</td>\n",
       "      <td>S</td>\n",
       "      <td>3.888998</td>\n",
       "      <td>1.845784</td>\n",
       "      <td>CD4_C03_CD44</td>\n",
       "      <td>CD4T</td>\n",
       "      <td>cd45</td>\n",
       "      <td>CD45</td>\n",
       "      <td>responder</td>\n",
       "      <td>pre</td>\n",
       "      <td>CD4</td>\n",
       "      <td>HCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P27-pre-T-CGTAGGCTCGCATGGC-1</th>\n",
       "      <td>P27-pre-T</td>\n",
       "      <td>T</td>\n",
       "      <td>P27</td>\n",
       "      <td>1205</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.720930</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3.813953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>8.418605</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1205</td>\n",
       "      <td>-0.219012</td>\n",
       "      <td>-0.135053</td>\n",
       "      <td>G1</td>\n",
       "      <td>9.128882</td>\n",
       "      <td>4.708649</td>\n",
       "      <td>NK_C03_GZMK</td>\n",
       "      <td>ILC</td>\n",
       "      <td>cd45</td>\n",
       "      <td>CD45</td>\n",
       "      <td>responder</td>\n",
       "      <td>pre</td>\n",
       "      <td>NK</td>\n",
       "      <td>HCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P11-pre-P-ACACCCTCAAGGCTCC-1</th>\n",
       "      <td>P11-pre-P</td>\n",
       "      <td>P</td>\n",
       "      <td>P11</td>\n",
       "      <td>2415</td>\n",
       "      <td>6466.0</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>16.408909</td>\n",
       "      <td>193.0</td>\n",
       "      <td>2.984844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.757810</td>\n",
       "      <td>0.120760</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2415</td>\n",
       "      <td>-0.131148</td>\n",
       "      <td>1.040371</td>\n",
       "      <td>G2M</td>\n",
       "      <td>4.558650</td>\n",
       "      <td>1.222805</td>\n",
       "      <td>NK_C01_FCGR3A</td>\n",
       "      <td>ILC</td>\n",
       "      <td>cd45</td>\n",
       "      <td>CD45</td>\n",
       "      <td>responder</td>\n",
       "      <td>pre</td>\n",
       "      <td>NK</td>\n",
       "      <td>HCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P5-pre-P-CTTCTCTAGGAGCGTT-1</th>\n",
       "      <td>P5-pre-P</td>\n",
       "      <td>P</td>\n",
       "      <td>P5</td>\n",
       "      <td>1578</td>\n",
       "      <td>4285.0</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>35.612602</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.843641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.653442</td>\n",
       "      <td>0.085366</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1578</td>\n",
       "      <td>0.022553</td>\n",
       "      <td>0.073411</td>\n",
       "      <td>G2M</td>\n",
       "      <td>-1.513131</td>\n",
       "      <td>-1.148967</td>\n",
       "      <td>CD4_C01_CCR7</td>\n",
       "      <td>CD4T</td>\n",
       "      <td>cd45</td>\n",
       "      <td>CD45</td>\n",
       "      <td>responder</td>\n",
       "      <td>pre</td>\n",
       "      <td>CD4</td>\n",
       "      <td>HCC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98270 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sample tissue patient  \\\n",
       "P16-pre-P-CD8p2-GGCGACTTCCACGTTC-1  P16-pre-P-CD8p      P     P16   \n",
       "P16-pre-P-CD8p1-CACCACTCAACAACCT-1  P16-pre-P-CD8p      P     P16   \n",
       "P16-pre-P-CD8n-TATTACCGTCCAACTA-1   P16-pre-P-CD8n      P     P16   \n",
       "P16-pre-T-CD8p-CTAATGGGTTCCATGA-1   P16-pre-T-CD8p      T     P16   \n",
       "P16-pre-P-CD8p1-TGACTTTAGCGTGAGT-1  P16-pre-P-CD8p      P     P16   \n",
       "...                                            ...    ...     ...   \n",
       "P18-pre-P-CTCTGGTCAGCGTAAG-1             P18-pre-P      P     P18   \n",
       "P27-pre-T-TGAGGGAAGAAGGCCT-1             P27-pre-T      T     P27   \n",
       "P27-pre-T-CGTAGGCTCGCATGGC-1             P27-pre-T      T     P27   \n",
       "P11-pre-P-ACACCCTCAAGGCTCC-1             P11-pre-P      P     P11   \n",
       "P5-pre-P-CTTCTCTAGGAGCGTT-1               P5-pre-P      P      P5   \n",
       "\n",
       "                                    n_genes_by_counts  total_counts  \\\n",
       "P16-pre-P-CD8p2-GGCGACTTCCACGTTC-1               1427        4671.0   \n",
       "P16-pre-P-CD8p1-CACCACTCAACAACCT-1               1835        7281.0   \n",
       "P16-pre-P-CD8n-TATTACCGTCCAACTA-1                 959        2529.0   \n",
       "P16-pre-T-CD8p-CTAATGGGTTCCATGA-1                1081        2505.0   \n",
       "P16-pre-P-CD8p1-TGACTTTAGCGTGAGT-1                894        1815.0   \n",
       "...                                               ...           ...   \n",
       "P18-pre-P-CTCTGGTCAGCGTAAG-1                     1396        2318.0   \n",
       "P27-pre-T-TGAGGGAAGAAGGCCT-1                     1319        3377.0   \n",
       "P27-pre-T-CGTAGGCTCGCATGGC-1                     1205        2150.0   \n",
       "P11-pre-P-ACACCCTCAAGGCTCC-1                     2415        6466.0   \n",
       "P5-pre-P-CTTCTCTAGGAGCGTT-1                      1578        4285.0   \n",
       "\n",
       "                                    total_counts_rp  pct_counts_rp  \\\n",
       "P16-pre-P-CD8p2-GGCGACTTCCACGTTC-1           1542.0      33.012203   \n",
       "P16-pre-P-CD8p1-CACCACTCAACAACCT-1           3163.0      43.441833   \n",
       "P16-pre-P-CD8n-TATTACCGTCCAACTA-1             996.0      39.383156   \n",
       "P16-pre-T-CD8p-CTAATGGGTTCCATGA-1             496.0      19.800400   \n",
       "P16-pre-P-CD8p1-TGACTTTAGCGTGAGT-1            353.0      19.449036   \n",
       "...                                             ...            ...   \n",
       "P18-pre-P-CTCTGGTCAGCGTAAG-1                  214.0       9.232097   \n",
       "P27-pre-T-TGAGGGAAGAAGGCCT-1                 1045.0      30.944624   \n",
       "P27-pre-T-CGTAGGCTCGCATGGC-1                   80.0       3.720930   \n",
       "P11-pre-P-ACACCCTCAAGGCTCC-1                 1061.0      16.408909   \n",
       "P5-pre-P-CTTCTCTAGGAGCGTT-1                  1526.0      35.612602   \n",
       "\n",
       "                                    total_counts_mt  pct_counts_mt  \\\n",
       "P16-pre-P-CD8p2-GGCGACTTCCACGTTC-1            154.0       3.296938   \n",
       "P16-pre-P-CD8p1-CACCACTCAACAACCT-1            264.0       3.625876   \n",
       "P16-pre-P-CD8n-TATTACCGTCCAACTA-1             231.0       9.134046   \n",
       "P16-pre-T-CD8p-CTAATGGGTTCCATGA-1              72.0       2.874251   \n",
       "P16-pre-P-CD8p1-TGACTTTAGCGTGAGT-1            205.0      11.294765   \n",
       "...                                             ...            ...   \n",
       "P18-pre-P-CTCTGGTCAGCGTAAG-1                   96.0       4.141501   \n",
       "P27-pre-T-TGAGGGAAGAAGGCCT-1                  137.0       4.056855   \n",
       "P27-pre-T-CGTAGGCTCGCATGGC-1                   82.0       3.813953   \n",
       "P11-pre-P-ACACCCTCAAGGCTCC-1                  193.0       2.984844   \n",
       "P5-pre-P-CTTCTCTAGGAGCGTT-1                    79.0       1.843641   \n",
       "\n",
       "                                    total_counts_hb  pct_counts_hb  \\\n",
       "P16-pre-P-CD8p2-GGCGACTTCCACGTTC-1              0.0            0.0   \n",
       "P16-pre-P-CD8p1-CACCACTCAACAACCT-1              0.0            0.0   \n",
       "P16-pre-P-CD8n-TATTACCGTCCAACTA-1               0.0            0.0   \n",
       "P16-pre-T-CD8p-CTAATGGGTTCCATGA-1               0.0            0.0   \n",
       "P16-pre-P-CD8p1-TGACTTTAGCGTGAGT-1              0.0            0.0   \n",
       "...                                             ...            ...   \n",
       "P18-pre-P-CTCTGGTCAGCGTAAG-1                    0.0            0.0   \n",
       "P27-pre-T-TGAGGGAAGAAGGCCT-1                    0.0            0.0   \n",
       "P27-pre-T-CGTAGGCTCGCATGGC-1                    0.0            0.0   \n",
       "P11-pre-P-ACACCCTCAAGGCTCC-1                    0.0            0.0   \n",
       "P5-pre-P-CTTCTCTAGGAGCGTT-1                     0.0            0.0   \n",
       "\n",
       "                                    total_counts_hsp  pct_counts_hsp  \\\n",
       "P16-pre-P-CD8p2-GGCGACTTCCACGTTC-1              13.0        0.278313   \n",
       "P16-pre-P-CD8p1-CACCACTCAACAACCT-1              15.0        0.206016   \n",
       "P16-pre-P-CD8n-TATTACCGTCCAACTA-1                8.0        0.316331   \n",
       "P16-pre-T-CD8p-CTAATGGGTTCCATGA-1               69.0        2.754491   \n",
       "P16-pre-P-CD8p1-TGACTTTAGCGTGAGT-1               9.0        0.495868   \n",
       "...                                              ...             ...   \n",
       "P18-pre-P-CTCTGGTCAGCGTAAG-1                    26.0        1.121657   \n",
       "P27-pre-T-TGAGGGAAGAAGGCCT-1                   131.0        3.879183   \n",
       "P27-pre-T-CGTAGGCTCGCATGGC-1                   181.0        8.418605   \n",
       "P11-pre-P-ACACCCTCAAGGCTCC-1                    49.0        0.757810   \n",
       "P5-pre-P-CTTCTCTAGGAGCGTT-1                     28.0        0.653442   \n",
       "\n",
       "                                    doublet_scores  predicted_doublets  \\\n",
       "P16-pre-P-CD8p2-GGCGACTTCCACGTTC-1        0.087618               False   \n",
       "P16-pre-P-CD8p1-CACCACTCAACAACCT-1        0.112999               False   \n",
       "P16-pre-P-CD8n-TATTACCGTCCAACTA-1         0.133690               False   \n",
       "P16-pre-T-CD8p-CTAATGGGTTCCATGA-1         0.064125               False   \n",
       "P16-pre-P-CD8p1-TGACTTTAGCGTGAGT-1        0.222841               False   \n",
       "...                                            ...                 ...   \n",
       "P18-pre-P-CTCTGGTCAGCGTAAG-1              0.137306               False   \n",
       "P27-pre-T-TGAGGGAAGAAGGCCT-1              0.045350               False   \n",
       "P27-pre-T-CGTAGGCTCGCATGGC-1              0.066667               False   \n",
       "P11-pre-P-ACACCCTCAAGGCTCC-1              0.120760               False   \n",
       "P5-pre-P-CTTCTCTAGGAGCGTT-1               0.085366               False   \n",
       "\n",
       "                                   doublet_info  n_genes   S_score  G2M_score  \\\n",
       "P16-pre-P-CD8p2-GGCGACTTCCACGTTC-1        False     1427  0.037808  -0.000656   \n",
       "P16-pre-P-CD8p1-CACCACTCAACAACCT-1        False     1835 -0.002969  -0.124453   \n",
       "P16-pre-P-CD8n-TATTACCGTCCAACTA-1         False      959 -0.188267  -0.082084   \n",
       "P16-pre-T-CD8p-CTAATGGGTTCCATGA-1         False     1081  0.139061   0.017359   \n",
       "P16-pre-P-CD8p1-TGACTTTAGCGTGAGT-1        False      894 -0.032617  -0.149058   \n",
       "...                                         ...      ...       ...        ...   \n",
       "P18-pre-P-CTCTGGTCAGCGTAAG-1              False     1396  0.041544  -0.059760   \n",
       "P27-pre-T-TGAGGGAAGAAGGCCT-1              False     1319  0.100014   0.030680   \n",
       "P27-pre-T-CGTAGGCTCGCATGGC-1              False     1205 -0.219012  -0.135053   \n",
       "P11-pre-P-ACACCCTCAAGGCTCC-1              False     2415 -0.131148   1.040371   \n",
       "P5-pre-P-CTTCTCTAGGAGCGTT-1               False     1578  0.022553   0.073411   \n",
       "\n",
       "                                   phase    UMAP_1    UMAP_2     sub_cluster  \\\n",
       "P16-pre-P-CD8p2-GGCGACTTCCACGTTC-1     S -0.212849  2.458946  CD8_C03_CX3CR1   \n",
       "P16-pre-P-CD8p1-CACCACTCAACAACCT-1    G1  7.944293 -0.144074    CD8_C01_LEF1   \n",
       "P16-pre-P-CD8n-TATTACCGTCCAACTA-1     G1  5.682766  3.407964  CD8_C02_GPR183   \n",
       "P16-pre-T-CD8p-CTAATGGGTTCCATGA-1      S  0.651383 -3.216115    CD8_C08_GZMK   \n",
       "P16-pre-P-CD8p1-TGACTTTAGCGTGAGT-1    G1  0.857628 -1.018432    CD8_C08_GZMK   \n",
       "...                                  ...       ...       ...             ...   \n",
       "P18-pre-P-CTCTGGTCAGCGTAAG-1           S  7.865705 -0.785990  CD8_C03_CX3CR1   \n",
       "P27-pre-T-TGAGGGAAGAAGGCCT-1           S  3.888998  1.845784    CD4_C03_CD44   \n",
       "P27-pre-T-CGTAGGCTCGCATGGC-1          G1  9.128882  4.708649     NK_C03_GZMK   \n",
       "P11-pre-P-ACACCCTCAAGGCTCC-1         G2M  4.558650  1.222805   NK_C01_FCGR3A   \n",
       "P5-pre-P-CTTCTCTAGGAGCGTT-1          G2M -1.513131 -1.148967    CD4_C01_CCR7   \n",
       "\n",
       "                                   major_cluster batch cell_type  \\\n",
       "P16-pre-P-CD8p2-GGCGACTTCCACGTTC-1           NaN   cd8      CD8T   \n",
       "P16-pre-P-CD8p1-CACCACTCAACAACCT-1           NaN   cd8      CD8T   \n",
       "P16-pre-P-CD8n-TATTACCGTCCAACTA-1            NaN   cd8      CD8T   \n",
       "P16-pre-T-CD8p-CTAATGGGTTCCATGA-1            NaN   cd8      CD8T   \n",
       "P16-pre-P-CD8p1-TGACTTTAGCGTGAGT-1           NaN   cd8      CD8T   \n",
       "...                                          ...   ...       ...   \n",
       "P18-pre-P-CTCTGGTCAGCGTAAG-1                CD8T  cd45      CD45   \n",
       "P27-pre-T-TGAGGGAAGAAGGCCT-1                CD4T  cd45      CD45   \n",
       "P27-pre-T-CGTAGGCTCGCATGGC-1                 ILC  cd45      CD45   \n",
       "P11-pre-P-ACACCCTCAAGGCTCC-1                 ILC  cd45      CD45   \n",
       "P5-pre-P-CTTCTCTAGGAGCGTT-1                 CD4T  cd45      CD45   \n",
       "\n",
       "                                         response pre_post Cell_Type  \\\n",
       "P16-pre-P-CD8p2-GGCGACTTCCACGTTC-1  non-responder      pre       CD8   \n",
       "P16-pre-P-CD8p1-CACCACTCAACAACCT-1  non-responder      pre       CD8   \n",
       "P16-pre-P-CD8n-TATTACCGTCCAACTA-1   non-responder      pre       CD8   \n",
       "P16-pre-T-CD8p-CTAATGGGTTCCATGA-1   non-responder      pre       CD8   \n",
       "P16-pre-P-CD8p1-TGACTTTAGCGTGAGT-1  non-responder      pre       CD8   \n",
       "...                                           ...      ...       ...   \n",
       "P18-pre-P-CTCTGGTCAGCGTAAG-1            responder      pre       CD8   \n",
       "P27-pre-T-TGAGGGAAGAAGGCCT-1            responder      pre       CD4   \n",
       "P27-pre-T-CGTAGGCTCGCATGGC-1            responder      pre        NK   \n",
       "P11-pre-P-ACACCCTCAAGGCTCC-1            responder      pre        NK   \n",
       "P5-pre-P-CTTCTCTAGGAGCGTT-1             responder      pre       CD4   \n",
       "\n",
       "                                   Cancer_type_update  \n",
       "P16-pre-P-CD8p2-GGCGACTTCCACGTTC-1                HCC  \n",
       "P16-pre-P-CD8p1-CACCACTCAACAACCT-1                HCC  \n",
       "P16-pre-P-CD8n-TATTACCGTCCAACTA-1                 HCC  \n",
       "P16-pre-T-CD8p-CTAATGGGTTCCATGA-1                 HCC  \n",
       "P16-pre-P-CD8p1-TGACTTTAGCGTGAGT-1                HCC  \n",
       "...                                               ...  \n",
       "P18-pre-P-CTCTGGTCAGCGTAAG-1                      HCC  \n",
       "P27-pre-T-TGAGGGAAGAAGGCCT-1                      HCC  \n",
       "P27-pre-T-CGTAGGCTCGCATGGC-1                      HCC  \n",
       "P11-pre-P-ACACCCTCAAGGCTCC-1                      HCC  \n",
       "P5-pre-P-CTTCTCTAGGAGCGTT-1                       HCC  \n",
       "\n",
       "[98270 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs['Cell_Type'] = adata.obs['sub_cluster'].apply(lambda x:x.split('_')[0])\n",
    "# 检查 pre_post 列是否存在\n",
    "import sys\n",
    "import pandas as pd\n",
    "if 'pre_post' not in adata.obs.columns:\n",
    "    print(\"adata.obs 中缺少 'pre_post' 列，程序退出\")\n",
    "    sys.exit()\n",
    "print(f\"pre_post 列的唯一值: {adata.obs['pre_post'].unique().tolist()}\")\n",
    "\n",
    "# 筛选 pre_post == 'Pre' 的行\n",
    "adata_ = adata[adata.obs['pre_post'] == 'pre'].copy()\n",
    "print(f\"筛选后 pre_post == 'pre' 的样本量: {adata_.shape[0]}\")\n",
    "adata_ = adata_[adata_.obs['pre_post'] == 'pre'].copy()\n",
    "print(f\"筛选后 pre_post == 'Pre' 的样本量: {adata_.shape[0]}\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "adata_.obs['Cancer_type_update'] = ['HCC']*adata_.obs.shape[0]\n",
    "adata_.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe288d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['P15-pre-P-GACGGCTGTACAGACG-1', 'P11-pre-P-GAGGTGATCTCCGGTT-1',\n",
       "       'P18-pre-T-CTGAAACTCCAGTATG-1', 'P5-pre-P-ATGGGAGTCTGGTTCC-1',\n",
       "       'P1-pre-P-CGAATGTCAGACAGGT-1', 'P16-pre-P-CD8p2-CGACCTTGTGCGGTAA-1',\n",
       "       'P18-pre-T-TGAGCATGTCGAATCT-1', 'P3-pre-P-CD8p-GTCCTCATCATACGGT-1',\n",
       "       'P3-pre-P-CD8p-GTTACAGGTCCGACGT-1', 'P27-pre-T-CGAATGTGTGGACGAT-1',\n",
       "       ...\n",
       "       'P5-pre-T-AGATCTGCAGCTGCTG-1', 'P18-pre-T-GACGGCTAGGAATGGA-1',\n",
       "       'P18-pre-T-GGGAGATAGACCCACC-1', 'P26-pre-P-CACCAGGGTTTACTCT-1',\n",
       "       'P5-pre-P-TAAACCGGTATAAACG-1', 'P16-pre-P-CD8p2-TGGGAAGTCTGCGTAA-1',\n",
       "       'P1-pre-P-ATGTGTGAGGTGACCA-1', 'P16-pre-P-CD8p1-GCGCAACTCAACCAAC-1',\n",
       "       'P11-pre-T-ACTTGTTAGATGTGGC-1', 'P16-pre-T-CD8p-TGGCTGGCAACACCTA-1'],\n",
       "      dtype='object', length=19486)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_test.obs.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56215f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample                    P15-pre-P\n",
       "tissue                            P\n",
       "patient                         P15\n",
       "n_genes_by_counts              1622\n",
       "total_counts                 4009.0\n",
       "total_counts_rp               673.0\n",
       "pct_counts_rp              16.78723\n",
       "total_counts_mt                63.0\n",
       "pct_counts_mt              1.571464\n",
       "total_counts_hb                 0.0\n",
       "pct_counts_hb                   0.0\n",
       "total_counts_hsp               51.0\n",
       "pct_counts_hsp             1.272138\n",
       "doublet_scores              0.11349\n",
       "predicted_doublets            False\n",
       "doublet_info                  False\n",
       "n_genes                        1622\n",
       "S_score                   -0.186944\n",
       "G2M_score                  0.105986\n",
       "phase                           G2M\n",
       "UMAP_1                     5.417911\n",
       "UMAP_2                    -1.114475\n",
       "sub_cluster           NK_C01_FCGR3A\n",
       "major_cluster                   ILC\n",
       "batch                          cd45\n",
       "cell_type                      CD45\n",
       "response              non-responder\n",
       "pre_post                        pre\n",
       "Cell_Type                        NK\n",
       "Cancer_type_update              HCC\n",
       "Name: P15-pre-P-GACGGCTGTACAGACG-1, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_test.obs.loc['P15-pre-P-GACGGCTGTACAGACG-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15528357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 77941 × 1000\n",
       "    obs: 'sample', 'tissue', 'patient', 'n_genes_by_counts', 'total_counts', 'total_counts_rp', 'pct_counts_rp', 'total_counts_mt', 'pct_counts_mt', 'total_counts_hb', 'pct_counts_hb', 'total_counts_hsp', 'pct_counts_hsp', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'n_genes', 'S_score', 'G2M_score', 'phase', 'UMAP_1', 'UMAP_2', 'sub_cluster', 'major_cluster', 'batch', 'cell_type', 'response', 'pre_post', 'Cell_Type', 'Cancer_type_update'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_train(adata,adata_test,cell_type):\n",
    "    gene = adata_test.var_names  \n",
    "    if cell_type == 'all':\n",
    "        adata_ = adata[adata.obs['Cell_Type'].isin(model_reult.keys()),gene]\n",
    "    else:\n",
    "        adata_ = adata[adata.obs['Cell_Type'] == cell_type,gene]\n",
    "    test_id = adata_test.obs.index\n",
    "    train_id = set(adata_.obs.index) - set(test_id)\n",
    "    adata_train =  adata_[list(train_id), :]\n",
    "    # print(adata_.shape,len(test_id),len(train_id))\n",
    "    return adata_train\n",
    "acc, auc_val, fpr, tpr, model, X_test, adata_test, le,metrics_list,types_clean,dflist =model_reult['all']['XGBoost']\n",
    "get_train(adata_,adata_test,'all') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6d7d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 285211 × 28913\n",
       "    obs: 'sample', 'tissue', 'patient', 'n_genes_by_counts', 'total_counts', 'total_counts_rp', 'pct_counts_rp', 'total_counts_mt', 'pct_counts_mt', 'total_counts_hb', 'pct_counts_hb', 'total_counts_hsp', 'pct_counts_hsp', 'doublet_scores', 'predicted_doublets', 'doublet_info', 'n_genes', 'S_score', 'G2M_score', 'phase', 'UMAP_1', 'UMAP_2', 'sub_cluster', 'major_cluster', 'batch', 'cell_type', 'response', 'pre_post', 'Cell_Type'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata[adata.obs['Cell_Type'].isin(model_reult.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd106411",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {}\n",
    "for types in model_reult:\n",
    "    acc, auc_val, fpr, tpr, model, X_test, adata_test, le,metrics_list,types_clean,dflist =model_reult[types]['XGBoost']\n",
    "    adata_train = get_train(adata_,adata_test,'all')\n",
    "    X_train = adata_train.X.toarray()   \n",
    "    y_train = [1 if i == 'responder' else 0 for i in adata_train.obs['response'].values]\n",
    "    train_data[types] = {\"adata_train\":adata_train,\n",
    "                        'X_train':X_train,\n",
    "                        'y_train':y_train}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f4bb15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def read_pickle(file:str):\n",
    "    data = pickle.load(open(file,'rb'))\n",
    "    return data\n",
    "def to_pickle(data,file):\n",
    "    pickle.dump(data,open(file,'wb'))\n",
    "# to_pickle(train_data,'/mnt/data/wangw/AFS/赵路晴/new_data/train_shap/train_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a86ab55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_clean = {}\n",
    "for types in model_reult:\n",
    "    acc, auc_val, fpr, tpr, model, X_test, adata_test, le,metrics_list,types_clean,dflist =model_reult[types]['XGBoost']\n",
    "    adata_train = get_train(adata_,adata_test,'all')\n",
    "    X_train = adata_train.X.toarray()   \n",
    "    y_train = [1 if i == 'responder' else 0 for i in adata_train.obs['response'].values]\n",
    "    train_data_clean[types] = {'gene':adata_test.var_names.tolist(),\n",
    "                        'X_train':X_train,\n",
    "                        'y_train':y_train}\n",
    "# to_pickle(train_data_clean,'/mnt/data/wangw/AFS/赵路晴/new_data/train_shap/train_data_clean.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a1f2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, pandas.core.indexes.base.Index)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(adata_test.var.index.tolist()), type(adata_test.var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94e4fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def read_pickle(file:str):\n",
    "    data = pickle.load(open(file,'rb'))\n",
    "    return data\n",
    "def to_pickle(data,file):\n",
    "    pickle.dump(data,open(file,'wb'))\n",
    "file ='/mnt/data/wangw/AFS/赵路晴/test/model_reult.pickle'\n",
    "model_reult = pickle.load(open(file,'rb'))\n",
    "train_data_clean = read_pickle('/mnt/data/wangw/AFS/赵路晴/new_data/train_shap/train_data_clean.pickle')\n",
    "import os\n",
    "import pandas as pd\n",
    "ENSEMBL_MAP = pd.read_csv(\"/mnt/data/wangw/ensemble-tran.csv\")\n",
    "ENSEMBL_DICT = dict(zip(ENSEMBL_MAP['ensembl'], ENSEMBL_MAP['feature']))\n",
    "os.environ[\"SCIPY_ARRAY_API\"] = \"1\"\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score, roc_auc_score,roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import pickle\n",
    "def shap_analysis(model, X_test, gene, types,model_name='XGBoots'):\n",
    "    file =f'/mnt/data/wangw/AFS/赵路晴/new_data/train_shap/feature_importance_{model_name}_{types}.pickle'\n",
    "    if not os.path.exists(file):\n",
    "        feature_names = gene\n",
    "        if isinstance(model, (RandomForestClassifier, LGBMClassifier, XGBClassifier, CatBoostClassifier)):\n",
    "            explainer = shap.TreeExplainer(model, feature_names=feature_names)\n",
    "        elif isinstance(model, LogisticRegression):\n",
    "            # explainer = shap.LinearExplainer(model, X_test, feature_perturbation=\"interventional\")\n",
    "            explainer = shap.LinearExplainer(model, X_test)\n",
    "        else:\n",
    "            print(f\"[警告] {str(model).split('(')[0]} 模型类型暂不支持 SHAP\")\n",
    "            # return None\n",
    "        # explainer = shap.TreeExplainer(model, model_output='probability')\n",
    "        # shap_values = explainer(X_test, check_additivity=False)\n",
    "        shap_values = explainer(X_test)\n",
    "        shap_vals = shap_values.values\n",
    "        if shap_vals.shape[1] == X_test.shape[1] and shap_vals.ndim == 3:  # 特征在中间（错误）\n",
    "            shap_vals = np.transpose(shap_vals, (0, 2, 1))\n",
    "        # if shap_vals.ndim == 3:\n",
    "            shap_mean = np.abs(shap_vals).mean(axis=(0, 1))\n",
    "        else:\n",
    "            shap_mean = np.abs(shap_vals).mean(axis=0)\n",
    "        \n",
    "        # print(\"shap_values.values shape:\", shap_values.values.shape)\n",
    "        # mean over samples & classes → shape (1000,)\n",
    "        ensembl_ids = gene\n",
    "        gene_names = [ENSEMBL_DICT.get(eid, eid) for eid in ensembl_ids]\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': gene_names,\n",
    "            'Mean SHAP Value': shap_mean\n",
    "        }).sort_values(by='Mean SHAP Value', ascending=False).reset_index(drop=True)\n",
    "        with open(file,'wb')as f:\n",
    "            pickle.dump(feature_importance,f)\n",
    "    else:\n",
    "        feature_importance = pickle.load(open(file,'rb'))\n",
    "    if not os.path.exists(f'/mnt/data/wangw/AFS/赵路晴/new_data/train_shap/{model_name}_shap_{types}.pdf'):\n",
    "        plt.figure()\n",
    "        shap.summary_plot(shap_values, X_test, feature_names=gene_names, plot_type='bar', show=False)\n",
    "        plt.title(f'SHAP Summary - {types}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'/mnt/data/wangw/AFS/赵路晴/new_data/train_shap/{model_name}_shap_{types}.pdf')\n",
    "        plt.close()\n",
    "    if not os.path.exists(f'/mnt/data/wangw/AFS/赵路晴/new_data/train_shap/{model_name}_shap_{types}.dot.pdf'):\n",
    "        print(f'{model_name}_shap_{types}.dot.pdf')\n",
    "        shap.summary_plot(shap_values, X_test, plot_type=\"dot\", show=False)\n",
    "        # fig = plt.gcf()\n",
    "        plt.savefig(f'/mnt/data/wangw/AFS/赵路晴/new_data/train_shap/{model_name}_shap_{types}.dot.pdf')\n",
    "        plt.close()\n",
    "    return feature_importance.head(10)\n",
    "\n",
    "\n",
    "# for types in model_reult:\n",
    "#     for model_name in model_reult[types]:\n",
    "#         print(types,model_name)\n",
    "#         acc, auc_val, fpr, tpr, model, X_test, adata_test, le,metrics_list,types_clean,dflist =model_reult[types][model_name]\n",
    "#         adata_train = train_data[types]['adata_train']\n",
    "#         X_train = train_data[types]['X_train']\n",
    "#         y_train = train_data[types]['y_train']\n",
    "#         shap_analysis(model, X_train, adata_train, types,model_name=model_name)\n",
    "        # shap_analysis(model, X_test, adata_test, types,model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72d7a68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "def worker(args):\n",
    "    # 拆包参数\n",
    "    model, X_train, gene, types, model_name = args\n",
    "    print(model_name,types)\n",
    "    try:\n",
    "        shap_analysis(model, X_train, gene, types, model_name=model_name)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# 构建参数列表\n",
    "task_list = []\n",
    "\n",
    "for types in model_reult:\n",
    "    for model_name in model_reult[types]:\n",
    "        file =f'/mnt/data/wangw/AFS/赵路晴/new_data/train_shap/feature_importance_{model_name}_{types}.pickle'\n",
    "        if not os.path.exists(file):\n",
    "            acc, auc_val, fpr, tpr, model, X_test, adata_test, le, metrics_list, types_clean, dflist = model_reult[types][model_name]\n",
    "            gene = train_data_clean[types]['gene']\n",
    "            X_train = train_data_clean[types]['X_train']\n",
    "            y_train = train_data_clean[types]['y_train']\n",
    "            task_list.append((model, X_train, gene, types, model_name))\n",
    "len(task_list)\n",
    "# print('start run!')\n",
    "# pool = Pool(16)\n",
    "# # # # 多进程执行\n",
    "# # with Pool(processes=4) as pool:  # 设置进程数，例如 4\n",
    "# pool.map(worker, task_list)\n",
    "# process_map(worker, task_list,max_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a238ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c13e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = '/mnt/data/wangw/AFS/赵路晴/new_data/train_shap'\n",
    "os.chdir(path)\n",
    "import glob\n",
    "# for file in os.listdir(path):\n",
    "# for file in glob.glob(f'feature*.pickle'):\n",
    "#     feature_df = read_pickle(file)\n",
    "#     feature_df.to_csv(file.replace('pickle','csv'),index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e124db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = '/mnt/data/wangw/AFS/赵路晴/new_data/train_shap'\n",
    "os.chdir(path)\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "857c6d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CD69', 'RGS1', 'FTH1', 'CCL4L2', 'B2M'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "top_features = feature_df['Feature'][:N].values\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fcdd6fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to function.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 210\u001b[39m\n\u001b[32m    202\u001b[39m     result[\u001b[33m'\u001b[39m\u001b[33mbest_th\u001b[39m\u001b[33m'\u001b[39m] = best_th\n\u001b[32m    203\u001b[39m     \u001b[38;5;66;03m# auc_scores = cross_val_score(clf, X_sub, y_train, cv=StratifiedKFold(5), scoring='roc_auc')\u001b[39;00m\n\u001b[32m    204\u001b[39m     \u001b[38;5;66;03m# results.append({\u001b[39;00m\n\u001b[32m    205\u001b[39m     \u001b[38;5;66;03m#     \"topN\": N,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    208\u001b[39m     \u001b[38;5;66;03m# })\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# 结果可视化\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     plt.plot(fpr, tpr, lw=\u001b[32m2\u001b[39m, label=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtop \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (95% CI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mci_lower\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mci_upper\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) | thr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_th\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    211\u001b[39m     plt.scatter(best_fpr, best_tpr, marker=\u001b[33m\"\u001b[39m\u001b[33mo\u001b[39m\u001b[33m\"\u001b[39m, color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m, s=\u001b[32m40\u001b[39m, zorder=\u001b[32m5\u001b[39m)\n\u001b[32m    212\u001b[39m plt.plot([\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m], [\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m], color=\u001b[33m\"\u001b[39m\u001b[33mgray\u001b[39m\u001b[33m\"\u001b[39m, lw=\u001b[32m1.5\u001b[39m, linestyle=\u001b[33m\"\u001b[39m\u001b[33m--\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: unsupported format string passed to function.__format__"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    roc_curve,confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "model_param_grid = {\n",
    "    \"Random Forest\": (RandomForestClassifier(random_state=42), {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [None, 5, 10]\n",
    "    }),\n",
    "    \"Logistic Regression\": (LogisticRegression(max_iter=1000), {\n",
    "        'C': [0.1, 1, 10]\n",
    "    }),\n",
    "    \"LightGBM\": (LGBMClassifier(verbose=-1,random_state=42,device='gpu'), {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [5, 10]\n",
    "    }),\n",
    "    \"CatBoost\": (CatBoostClassifier(task_type='GPU',verbose=0, random_state=42), {\n",
    "        'iterations': [100, 200],\n",
    "        'depth': [4, 6]\n",
    "    }),\n",
    "    \"XGBoost\": (XGBClassifier(tree_method = \"hist\", device = \"cuda\", eval_metric='logloss', random_state=42), {\n",
    "        \"max_depth\": [\n",
    "            3,\n",
    "            5,\n",
    "            7,\n",
    "            10\n",
    "        ],\n",
    "        \"learning_rate\": [\n",
    "            0.01,\n",
    "            0.05,\n",
    "            0.1,\n",
    "            0.3\n",
    "        ],\n",
    "        \"n_estimators\": [\n",
    "            50,\n",
    "            100,\n",
    "            200,\n",
    "            300\n",
    "        ],\n",
    "        \"reg_lambda\": [\n",
    "            0.1,\n",
    "            1.0,\n",
    "            10.0,\n",
    "            100.0\n",
    "        ],\n",
    "        \"reg_alpha\": [\n",
    "            0.0,\n",
    "            0.5,\n",
    "            1.0,\n",
    "            5.0\n",
    "        ],\n",
    "        \"subsample\": [\n",
    "            0.6,\n",
    "            0.8,\n",
    "            1.0\n",
    "        ],\n",
    "        \"colsample_bytree\": [\n",
    "            0.6,\n",
    "            0.8,\n",
    "            1.0\n",
    "        ]\n",
    "    }),\n",
    " \n",
    "}\n",
    "random_seed =42\n",
    "# 假设 shap_importance 是 pd.Series，index 是特征名，value 是 mean(|SHAP|)\n",
    "def compute_roc_auc_ci(y_true, y_scores, n_bootstraps=1000, alpha=0.95):\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    bootstrapped_scores = []\n",
    "    # y_true = y_true.to_numpy() if isinstance(y_true, pd.Series) else y_true\n",
    "    y_true = np.array(y_true)\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = rng.randint(0, len(y_scores), len(y_scores))\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue\n",
    "        score = roc_auc_score(y_true[indices], y_scores[indices])\n",
    "        bootstrapped_scores.append(score)\n",
    "\n",
    "    sorted_scores = np.array(bootstrapped_scores)\n",
    "    sorted_scores.sort()\n",
    "    lower = sorted_scores[int((1.0 - alpha) / 2 * len(sorted_scores))]\n",
    "    upper = sorted_scores[int((1.0 + alpha) / 2 * len(sorted_scores))]\n",
    "    return lower, upper\n",
    "\n",
    "def plot_merge(feature_df,cell,X_train,y_train,X_test,y_test):\n",
    "    results = []\n",
    "    top_feature_counts = [5, 10, 20, 30, 50, 100,200]\n",
    "    plt.figure(figsize=(10,8))\n",
    "    for N in top_feature_counts:\n",
    "        \n",
    "        top_features = feature_df['Feature'][:N].values\n",
    "        X_train_ = X_train[top_features]\n",
    "        X_test_ = X_test[top_features]\n",
    "        # clf = XGBClassifier( eval_metric='logloss', random_state=42)\n",
    "        \n",
    "        cv = 5\n",
    "        model,param_grid = model_param_grid[model_name]\n",
    "        grid = RandomizedSearchCV(model, param_grid, cv=cv, scoring='roc_auc', n_jobs=1, verbose=0) #gpu\n",
    "        grid.fit(X_train_, y_train)\n",
    "        print(f\"Best AUROC (CV): {grid.best_score_:.4f}\")\n",
    "        print(f\"Best Params: {grid.best_params_}\")\n",
    "        best_model = grid.best_estimator_\n",
    "        y_test_pred = best_model.predict(X_test_)\n",
    "        y_test_proba = best_model.predict_proba(X_test_)[:, 1]\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        test_fpr, test_tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "        test_auc = auc(test_fpr, test_tpr)\n",
    "        # auc_scores = cross_val_score(clf, X_sub, y_train, cv=StratifiedKFold(5), scoring='roc_auc')\n",
    "        results.append({\n",
    "            \"topN\": N,\n",
    "            \"auc\": test_acc,\n",
    "            \"roc_curve\": (test_fpr, test_tpr)\n",
    "        })\n",
    "        # results.append({\n",
    "        #     \"topN\": N,\n",
    "        #     \"mean_auc\": auc_scores.mean(),\n",
    "        #     \"std_auc\": auc_scores.std()\n",
    "        # })\n",
    "    # 结果可视化\n",
    "        plt.plot(test_fpr, test_tpr, lw=2, label=f\"{model_name} (AUC = {test_acc:.3f})\")\n",
    "\n",
    "    plt.plot([0,1], [0,1], color=\"gray\", lw=1.5, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "    plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "    plt.title(f\"ROC Curves of top {N} SHAP Features : {cell}_{model_name}\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    # plt.save_fig()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "for types in model_reult:\n",
    "    # for model_name in model_reult[types]:\n",
    "    model_name = 'XGBoost'\n",
    "    file =f'/mnt/data/wangw/AFS/赵路晴/new_data/train_shap/feature_importance_{model_name}_{types}.pickle'\n",
    "    feature_df = read_pickle(file)\n",
    "\n",
    "    gene = train_data_clean[types]['gene']\n",
    "    acc, auc_val, fpr, tpr, model, X_test, adata_test, le, metrics_list, types_clean, dflist = model_reult[types][model_name]\n",
    "    X_train = train_data_clean[types]['X_train']\n",
    "    X_train = pd.DataFrame(X_train,columns=gene)\n",
    "    X_test= pd.DataFrame(X_test,columns=gene)\n",
    "    y_train = train_data_clean[types]['y_train']\n",
    "    y_test = [1 if i == 'responder' else 0 for i in adata_test.obs['response'].values]\n",
    "    # plot_merge(feature_df,types,X_train,y_train,X_test,y_test)\n",
    "    result = {}\n",
    "    top_feature_counts = [5, 10, 20, 50, 100,200]\n",
    "    plt.figure(figsize=(10,8))\n",
    "    # with open()as f:\n",
    "    for N in top_feature_counts:\n",
    "        \n",
    "        top_features = feature_df['Feature'][:N].values\n",
    "        X_train_ = X_train[top_features]\n",
    "        X_test_ = X_test[top_features]\n",
    "        # clf = XGBClassifier( eval_metric='logloss', random_state=42)\n",
    "        \n",
    "        cv = 5\n",
    "        model,param_grid = model_param_grid[model_name]\n",
    "        grid = RandomizedSearchCV(model, param_grid, cv=cv, scoring='roc_auc', n_jobs=1, verbose=0) #gpu\n",
    "        grid.fit(X_train_, y_train)\n",
    "        # print(f\"Best AUROC (CV): {grid.best_score_:.4f}\")\n",
    "        # print(f\"Best Params: {grid.best_params_}\")\n",
    "        best_model = grid.best_estimator_\n",
    "        y_test_pred = best_model.predict(X_test_)\n",
    "        y_test_proba = best_model.predict_proba(X_test_)[:, 1]\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
    "        test_auc = auc(test_fpr, test_tpr)\n",
    "        ci_lower, ci_upper = compute_roc_auc_ci(y_test, y_test_pred)\n",
    "        acc = accuracy_score(y_test, y_test_pred)\n",
    "        precision = precision_score(y_test, y_test_pred)\n",
    "        recall = recall_score(y_test, y_test_pred)\n",
    "        f1 = f1_score(y_test, y_test_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "        J_scores = tpr - fpr\n",
    "        idx = np.argmax(J_scores)\n",
    "        best_fpr, best_tpr, best_th = fpr[idx], tpr[idx], thresholds[idx]\n",
    "\n",
    "        conf_matrix = {\n",
    "                    \"TP\": int(tp),\n",
    "                    \"TN\": int(tn),\n",
    "                    \"FP\": int(fp),\n",
    "                    \"FN\": int(fn)\n",
    "                    }\n",
    "        result['acc']=acc\n",
    "        result['precision']=precision\n",
    "        result['recall']=recall\n",
    "        result['f1']=f1\n",
    "        result['auc']=auc\n",
    "        result['fpr']=fpr\n",
    "        result['tpr']=tpr\n",
    "        result['acc']=acc\n",
    "        result['auc_ci']=(ci_lower, ci_upper)\n",
    "        result['confusion_matrix']=conf_matrix\n",
    "        result['best_th'] = best_th\n",
    "        # auc_scores = cross_val_score(clf, X_sub, y_train, cv=StratifiedKFold(5), scoring='roc_auc')\n",
    "        # results.append({\n",
    "        #     \"topN\": N,\n",
    "        #     \"auc\": test_acc,\n",
    "        #     \"roc_curve\": (test_fpr, test_tpr)\n",
    "        # })\n",
    "    # 结果可视化\n",
    "        plt.plot(fpr, tpr, lw=2, label=f\"top {N}: AUC: {auc:.4f} (95% CI: {ci_lower:.4f} - {ci_upper:.4f}) | thr={best_th:.2f}\")\n",
    "        plt.scatter(best_fpr, best_tpr, marker=\"o\", color=\"red\", s=40, zorder=5)\n",
    "    plt.plot([0,1], [0,1], color=\"gray\", lw=1.5, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "    plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "    plt.title(f\"ROC Curves of top SHAP Features : {types}_{model_name}\")\n",
    "    plt.legend(loc=\"lower right\", frameon=False)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    # plt.save_fig()\n",
    "    plt.show()\n",
    "    # plt.close()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184252e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_clean[types]['gene']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2116c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel(n_jobs=16)(\n",
    "#     delayed(worker)(model, X_train, gene, types, model_name)\n",
    "#     for types in model_reult\n",
    "#     for model_name in model_reult[types]\n",
    "#     for (acc, auc_val, fpr, tpr, model, X_test, adata_test, le, metrics_list, types_clean, dflist)\n",
    "#         in [model_reult[types][model_name]]\n",
    "#     for gene in [train_data_clean[types]['gene']]\n",
    "#     for X_train in [train_data_clean[types]['X_train']]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0421e563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19744, 16499)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>P01_T_0001</th>\n",
       "      <th>P01_T_0003</th>\n",
       "      <th>P01_T_0004</th>\n",
       "      <th>P01_T_0007</th>\n",
       "      <th>P01_T_0008</th>\n",
       "      <th>P01_T_0011</th>\n",
       "      <th>P01_T_0013</th>\n",
       "      <th>P01_T_0014</th>\n",
       "      <th>P01_T_0015</th>\n",
       "      <th>...</th>\n",
       "      <th>P19_T_0124</th>\n",
       "      <th>P19_T_0126</th>\n",
       "      <th>P19_T_0128</th>\n",
       "      <th>P19_T_0129</th>\n",
       "      <th>P19_T_0134</th>\n",
       "      <th>P19_T_0138</th>\n",
       "      <th>P19_T_0139</th>\n",
       "      <th>P19_T_0143</th>\n",
       "      <th>P19_T_0144</th>\n",
       "      <th>P19_T_0146</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OR4F5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FO538757.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FO538757.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OR4F29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OR4F16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16499 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gene  P01_T_0001  P01_T_0003  P01_T_0004  P01_T_0007  P01_T_0008  \\\n",
       "0       OR4F5         0.0         0.0         0.0         0.0         0.0   \n",
       "1  FO538757.2         0.0         0.0         0.0         0.0         0.0   \n",
       "2  FO538757.1         0.0         0.0         0.0         0.0         0.0   \n",
       "3      OR4F29         0.0         0.0         0.0         0.0         0.0   \n",
       "4      OR4F16         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   P01_T_0011  P01_T_0013  P01_T_0014  P01_T_0015  ...  P19_T_0124  \\\n",
       "0         0.0         0.0         0.0         0.0  ...       0.000   \n",
       "1         0.0         0.0         0.0         0.0  ...       0.000   \n",
       "2         0.0         0.0         0.0         0.0  ...       0.157   \n",
       "3         0.0         0.0         0.0         0.0  ...       0.000   \n",
       "4         0.0         0.0         0.0         0.0  ...       0.000   \n",
       "\n",
       "   P19_T_0126  P19_T_0128  P19_T_0129  P19_T_0134  P19_T_0138  P19_T_0139  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0      0.0000   \n",
       "1         0.0         0.0         0.0         0.0         0.0      0.0000   \n",
       "2         0.0         0.0         0.0         0.0         0.0      0.0677   \n",
       "3         0.0         0.0         0.0         0.0         0.0      0.0000   \n",
       "4         0.0         0.0         0.0         0.0         0.0      0.0000   \n",
       "\n",
       "   P19_T_0143  P19_T_0144  P19_T_0146  \n",
       "0      0.0000         0.0         0.0  \n",
       "1      0.0000         0.0         0.0  \n",
       "2      0.0488         0.0         0.0  \n",
       "3      0.0000         0.0         0.0  \n",
       "4      0.0000         0.0         0.0  \n",
       "\n",
       "[5 rows x 16499 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/mnt/data/wangw/AFS/赵路晴/new_data/data_with_responder/CNP0000650/Single_Cell/CSE0000008/HCC_log_tpm_expression_matrix.txt',sep='\\t')\n",
    "print(df.shape)\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f8bfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OR4F5</th>\n",
       "      <th>FO538757.2</th>\n",
       "      <th>FO538757.1</th>\n",
       "      <th>OR4F29</th>\n",
       "      <th>OR4F16</th>\n",
       "      <th>SAMD11</th>\n",
       "      <th>NOC2L</th>\n",
       "      <th>KLHL17</th>\n",
       "      <th>PLEKHN1</th>\n",
       "      <th>PERM1</th>\n",
       "      <th>...</th>\n",
       "      <th>AC007325.4</th>\n",
       "      <th>AC007325.2</th>\n",
       "      <th>BX072566.1</th>\n",
       "      <th>AL354822.1</th>\n",
       "      <th>AC023491.2</th>\n",
       "      <th>AC004556.1</th>\n",
       "      <th>AC233755.2</th>\n",
       "      <th>AC233755.1</th>\n",
       "      <th>AC240274.1</th>\n",
       "      <th>AC213203.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P01_T_0001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0862</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P01_T_0003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P01_T_0004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P01_T_0007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P01_T_0008</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19744 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            OR4F5  FO538757.2  FO538757.1  OR4F29  OR4F16  SAMD11   NOC2L  \\\n",
       "P01_T_0001    0.0         0.0         0.0     0.0     0.0     0.0  0.2070   \n",
       "P01_T_0003    0.0         0.0         0.0     0.0     0.0     0.0  0.1040   \n",
       "P01_T_0004    0.0         0.0         0.0     0.0     0.0     0.0  0.0770   \n",
       "P01_T_0007    0.0         0.0         0.0     0.0     0.0     0.0  0.0198   \n",
       "P01_T_0008    0.0         0.0         0.0     0.0     0.0     0.0  0.4640   \n",
       "\n",
       "            KLHL17  PLEKHN1  PERM1  ...  AC007325.4  AC007325.2  BX072566.1  \\\n",
       "P01_T_0001     0.0      0.0    0.0  ...      2.5100         0.0         0.0   \n",
       "P01_T_0003     0.0      0.0    0.0  ...      0.0392         0.0         0.0   \n",
       "P01_T_0004     0.0      0.0    0.0  ...      0.0000         0.0         0.0   \n",
       "P01_T_0007     0.0      0.0    0.0  ...      0.0000         0.0         0.0   \n",
       "P01_T_0008     0.0      0.0    0.0  ...      0.0000         0.0         0.0   \n",
       "\n",
       "            AL354822.1  AC023491.2  AC004556.1  AC233755.2  AC233755.1  \\\n",
       "P01_T_0001        0.00      0.3920         0.0         0.0         0.0   \n",
       "P01_T_0003        3.33      0.0000         0.0         0.0         0.0   \n",
       "P01_T_0004        0.00      0.0392         0.0         0.0         0.0   \n",
       "P01_T_0007        0.00      0.0000         0.0         0.0         0.0   \n",
       "P01_T_0008        0.00      0.0000         0.0         0.0         0.0   \n",
       "\n",
       "            AC240274.1  AC213203.1  \n",
       "P01_T_0001      0.0862         0.0  \n",
       "P01_T_0003      0.4050         0.0  \n",
       "P01_T_0004      0.0000         0.0  \n",
       "P01_T_0007      0.0000         0.0  \n",
       "P01_T_0008      0.0000         0.0  \n",
       "\n",
       "[5 rows x 19744 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index= df['gene'].values\n",
    "df = df.drop(columns=['gene'])\n",
    "df.T[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c51740fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.to_csv('/mnt/data/wangw/AFS/赵路晴/new_data/data_with_responder/CNP0000650/Single_Cell/CSE0000008/expression.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
